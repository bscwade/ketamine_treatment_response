{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from factor_analyzer.factor_analyzer import calculate_kmo\n",
    "import sklearn\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report, precision_score, recall_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, cross_validate, GridSearchCV, KFold, StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV, SelectKBest, SelectFromModel, f_classif\n",
    "from sklearn.pipeline import Pipeline\n",
    "from functools import reduce\n",
    "import pickle\n",
    "import itertools\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.stats.multicomp as mc\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "timepoint_end='followup' # 'end_of_treatment' or 'followup'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 448)\n"
     ]
    }
   ],
   "source": [
    "def load_data(timepoint_end):\n",
    "    if timepoint_end=='end_of_treatment':\n",
    "        dem=pd.read_csv('../data/ketamine_endtreatment_hdrs.csv', index_col=[0])\n",
    "    else:\n",
    "        dem=pd.read_csv('../data/ketamine_followup_hdrs.csv', index_col=[0])\n",
    "\n",
    "    img=pd.read_csv('../data/baseline_rsfc-yeo17_diffusion.csv', index_col=[0])\n",
    "    df=dem.merge(img, on='screen_id')\n",
    "    print(df.shape)\n",
    "    return df\n",
    "\n",
    "df=load_data(timepoint_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iMSA: [0.62502512 0.57444776 0.46678683 0.66906508 0.48038619 0.30801207\n",
      " 0.48403207 0.64859315 0.43608313 0.5628611  0.55868638 0.63590734\n",
      " 0.48166926 0.49856915 0.59764058 0.50340844 0.53068733] \n",
      "\n",
      "Overall MSA: 0.5366922316301637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/factor_analyzer/utils.py:248: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn('The inverse of the variance-covariance matrix '\n"
     ]
    }
   ],
   "source": [
    "def get_kmo():\n",
    "    data_for_fa=pd.read_csv('../data/ketamine_endtreatment_hdrs.csv', index_col=[0]) # factor analysis done with e.o.t. data; larger sample\n",
    "    hdrs_for_fa=data_for_fa[data_for_fa.columns[data_for_fa.columns.to_series().str.contains('baseline')]]\n",
    "    kmo=calculate_kmo(hdrs_for_fa)\n",
    "    print('iMSA: {} \\n'.format(kmo[0]))\n",
    "    print('Overall MSA: {}'.format(kmo[1]))\n",
    "get_kmo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in Factor 1: \n",
      " Index(['hamd_depressed_mood_change', 'hamd_guilt_change',\n",
      "       'hamd_suicide_change', 'hamd_activities_change',\n",
      "       'hamd_retardation_change', 'hamd_somsxs_gastro_change'],\n",
      "      dtype='object') \n",
      "\n",
      "Items in Factor 2: \n",
      " Index(['hamd_insomnia_early_change', 'hamd_insomnia_middle_change',\n",
      "       'hamd_anxiety_psychic_change', 'hamd_anxiety_somatic_change',\n",
      "       'hamd_somsxs_general_change', 'hamd_hypochondriasis_change'],\n",
      "      dtype='object') \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_factor_items(n_factors, threshold):\n",
    "    data_for_fa=pd.read_csv('../data/ketamine_endtreatment_hdrs.csv', index_col=[0]) # factor analysis done with e.o.t. data; larger sample\n",
    "    hdrs_for_fa=data_for_fa[data_for_fa.columns[data_for_fa.columns.to_series().str.contains('baseline')]]\n",
    "    hdrs_change=data_for_fa[data_for_fa.columns[data_for_fa.columns.to_series().str.contains('change')]]\n",
    "    fa=FactorAnalyzer(n_factors=n_factors, rotation='oblimin', is_corr_matrix=False)\n",
    "    fa.fit(hdrs_for_fa)\n",
    "    loadings_bool=np.abs(fa.loadings_)>threshold\n",
    "    items=[ hdrs_change.columns[loadings_bool[:,x]] for x in range(n_factors) ]\n",
    "        \n",
    "    for idx, itemset in enumerate(items):\n",
    "        print('Items in Factor {}: \\n {} \\n'.format(idx+1, itemset))    \n",
    "    return items\n",
    "\n",
    "fitems=get_factor_items(n_factors=2, threshold=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Factor_1</th>\n",
       "      <th>Factor_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-8</td>\n",
       "      <td>-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-9</td>\n",
       "      <td>-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Factor_1  Factor_2\n",
       "0        -8        -8\n",
       "1        -7         3\n",
       "2        -9       -10\n",
       "3        -7        -4\n",
       "4        -5         0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_factor_scores(data, items):\n",
    "    tmp={}\n",
    "    for i in range(len(items)):\n",
    "        tmp['Factor_{}'.format(i+1)]=data[items[i]].sum(axis=1)\n",
    "    tmp_df=pd.DataFrame.from_dict(tmp)\n",
    "    return(tmp_df)\n",
    "\n",
    "def compute_factor_scores_baseline(data, items):\n",
    "    tmp={}\n",
    "    for i in range(len(items)):\n",
    "        items_baseline=[x.replace('_change', '_baseline') for x in items[i]]\n",
    "        tmp['Factor_{}'.format(i+1)]=data[items_baseline].sum(axis=1)\n",
    "    tmp_df=pd.DataFrame.from_dict(tmp)\n",
    "    return(tmp_df)\n",
    "\n",
    "factor_df=compute_factor_scores(df, fitems)\n",
    "baseline_factor_df=compute_factor_scores_baseline(df, fitems)\n",
    "factor_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframes for baseline and hdrs change\n",
    "hdrs_df=pd.DataFrame({\n",
    "    'hdrs_17_change': df[df.columns[df.columns.to_series().str.contains('change')]].sum(axis=1),\n",
    "    'hdrs_6_change': df[['hamd_depressed_mood_change', 'hamd_guilt_change', 'hamd_activities_change','hamd_retardation_change', 'hamd_anxiety_psychic_change', 'hamd_somsxs_general_change']].sum(axis=1)    \n",
    "})\n",
    "hdrs_df=hdrs_df.merge(factor_df, right_index=True, left_index=True)\n",
    "hdrs_df.head()\n",
    "\n",
    "hdrs_df_baseline=pd.DataFrame({\n",
    "    'hdrs_17_baseline': df[df.columns[df.columns.to_series().str.contains('baseline')]].sum(axis=1),\n",
    "    'hdrs_6_baseline': df[['hamd_depressed_mood_baseline', 'hamd_guilt_baseline', 'hamd_activities_baseline','hamd_retardation_baseline', 'hamd_anxiety_psychic_baseline', 'hamd_somsxs_general_baseline']].sum(axis=1)    \n",
    "})\n",
    "hdrs_df_baseline=hdrs_df_baseline.merge(baseline_factor_df, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_xy(hdrs_change, hdrs_baseline, data, outcome):    \n",
    "    outcome_bin_tmp=(hdrs_change[outcome]/hdrs_baseline[outcome.replace('change', 'baseline')]) <= -0.5\n",
    "    img=pd.read_csv('../data/baseline_rsfc-yeo17_diffusion.csv', index_col=[0])\n",
    "    lb=preprocessing.LabelBinarizer()\n",
    "    lb.fit(outcome_bin_tmp)\n",
    "    y_bin=lb.fit_transform(outcome_bin_tmp)\n",
    "    X=df[img.columns].drop(['screen_id'], axis=1)\n",
    "    return X,y_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_xy(hdrs_change=hdrs_df, hdrs_baseline=hdrs_df_baseline, data=df, outcome='Factor_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 1)\n",
      "(60, 411)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer=SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "rf_mod=RandomForestClassifier(n_jobs=10, random_state=0)\n",
    "rf_pipeline=Pipeline([('imputation', imputer), ('selection', SelectKBest(f_classif)), ('random_forest', rf_mod)])\n",
    "\n",
    "gb_mod=GradientBoostingClassifier(random_state=0)\n",
    "gb_pipeline=Pipeline([('imputation', imputer), ('selection', SelectKBest(f_classif)), ('gb_regressor', gb_mod)])\n",
    "\n",
    "svm_mod=SVC(kernel='linear')\n",
    "svm_pipeline=Pipeline([('imputation', imputer), ('scale', StandardScaler()), ('selection', SelectKBest(f_classif)), ('sv_regressor', svm_mod)])\n",
    "\n",
    "log_mod=LogisticRegression()\n",
    "log_pipeline=Pipeline([('imputation', imputer), ('scale', StandardScaler()), ('selection', SelectKBest(f_classif)), ('log_regressor', log_mod)])\n",
    "\n",
    "pipelines=[rf_pipeline, gb_pipeline, svm_pipeline, log_pipeline]\n",
    "pipe_dict={0: 'RF', 1: 'GB', 2: 'SVM', 3: 'LOG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_grid={'random_forest__n_estimators': [100, 500, 1000],\n",
    "        'random_forest__max_depth': [2, 4, 6],\n",
    "        'selection__k': [10, 20, 30]}\n",
    "\n",
    "gb_grid={'gb_regressor__n_estimators': [25, 50, 100],\n",
    "        'gb_regressor__learning_rate': [0.05, 0.1, 0.3],\n",
    "        'gb_regressor__max_depth': [2, 4, 6],\n",
    "        'gb_regressor__min_samples_split': [2, 4],\n",
    "        'gb_regressor__min_samples_leaf': [1],\n",
    "        'selection__k': [10, 20, 30]}\n",
    "\n",
    "svr_grid={'sv_regressor__C': [0.01, 0.1, 1, 10],\n",
    "         'selection__k': [10, 20, 30]}\n",
    "\n",
    "log_grid={'log_regressor__penalty': ['l2']}\n",
    "\n",
    "parameter_grid_list=[rf_grid, gb_grid, svr_grid, log_grid]\n",
    "\n",
    "inner_cv = KFold(n_splits=10, shuffle=False, random_state=0)\n",
    "outer_cv = KFold(n_splits=10, shuffle=False, random_state=0)\n",
    "\n",
    "# clf = GridSearchCV(estimator=gb_pipeline, param_grid=gb_grid, cv=inner_cv)\n",
    "# nested_score = cross_val_predict(clf, X=X, y=y, cv=outer_cv)\n",
    "# print(r2_score(y_true=y, y_pred=nested_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_dict={}\n",
    "# for i, pipe in enumerate(pipelines):\n",
    "#     print('Processing {} model for outcome {}...'.format(pipe_dict[i], 'factor 1'))\n",
    "#     clf=GridSearchCV(estimator=pipe, param_grid=parameter_grid_list[i], cv=inner_cv)\n",
    "#     predicted=cross_val_predict(clf, X=X, y=y_bin.ravel(), cv=outer_cv)\n",
    "#     predicted_dict[pipe_dict[i]]=predicted\n",
    "#     print('{} f1 score: {:2f}; balanced acc.: {:2f} \\n'.format(pipe_dict[i], f1_score(y_true=y_bin.ravel(), y_pred=predicted), balanced_accuracy_score(y_true=y_bin.ravel(), y_pred=predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdrs_17_change \n",
      "\n",
      "Processing RF model for outcome hdrs_17_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.591667 +/- 0.141667\n",
      "Processing GB model for outcome hdrs_17_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.625000 +/- 0.182574\n",
      "Processing SVM model for outcome hdrs_17_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.583333 +/- 0.199826\n",
      "Processing LOG model for outcome hdrs_17_change\n",
      "Ave BA 0.700000 +/- 0.163299\n",
      "hdrs_6_change \n",
      "\n",
      "Processing RF model for outcome hdrs_6_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.500000 +/- 0.140683\n",
      "Processing GB model for outcome hdrs_6_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.591667 +/- 0.160078\n",
      "Processing SVM model for outcome hdrs_6_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.554167 +/- 0.136994\n",
      "Processing LOG model for outcome hdrs_6_change\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.505000 +/- 0.158605\n",
      "Factor_1 \n",
      "\n",
      "Processing RF model for outcome Factor_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.616667 +/- 0.176580\n",
      "Processing GB model for outcome Factor_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.594167 +/- 0.152573\n",
      "Processing SVM model for outcome Factor_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.615000 +/- 0.119304\n",
      "Processing LOG model for outcome Factor_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1859: UserWarning: y_pred contains classes not in y_true\n",
      "  warnings.warn('y_pred contains classes not in y_true')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ave BA 0.630000 +/- 0.099037\n",
      "Factor_2 \n",
      "\n",
      "Processing RF model for outcome Factor_2\n",
      "Ave BA 0.435833 +/- 0.215318\n",
      "Processing GB model for outcome Factor_2\n",
      "Ave BA 0.428333 +/- 0.243048\n",
      "Processing SVM model for outcome Factor_2\n",
      "Ave BA 0.515000 +/- 0.193857\n",
      "Processing LOG model for outcome Factor_2\n",
      "Ave BA 0.440000 +/- 0.260550\n"
     ]
    }
   ],
   "source": [
    "for outcome in ['hdrs_17_change', 'hdrs_6_change', 'Factor_1', 'Factor_2']:\n",
    "    print('{} \\n'.format(outcome))\n",
    "    X,y=make_xy(hdrs_change=hdrs_df, hdrs_baseline=hdrs_df_baseline, data=df, outcome=outcome)\n",
    "    \n",
    "    for i, pipe in enumerate(pipelines):\n",
    "        print('Processing {} model for outcome {}'.format(pipe_dict[i], outcome))\n",
    "        clf=GridSearchCV(estimator=pipe, param_grid=parameter_grid_list[i], cv=inner_cv)\n",
    "        res=cross_val_score(clf, X, y.ravel(), cv=outer_cv, scoring='balanced_accuracy')\n",
    "        print('Ave BA {:2f} +/- {:2f}'.format(np.mean(res), np.std(res)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
